# -*- coding: utf-8 -*-
"""case_prophet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1717qsq4dYVEs2TGpEMHOQIxW0cN6VSTa

## <font color=Green>Forecasting air transport passengers </font>

<br>


We have time series data at hand showing passengers carried in a set of countries over the world.
A data product which could be developed, for the airline industry (or a specific airline) could be a prediction of the development in the trend for the next few years*.
For a global airline, or an industry association, this data could inform corporate strategy decisions: market-level growth rates could be compared across countries, to help assess which could be more attractive and steer resource allocation where it matters the most.

For simplicity, we can the Facebook Prophet** model, a well-known time series forecasting algorithm developed by Facebook, and pick a couple countries to provide a proof of concept.

Note 1: Our data does not include COVID, which affected the industry quite a bit, so this is a clear limitation 

Note 2: https://facebook.github.io/prophet/

Some info about Prophet:

- Prophet is open source software released by Facebookâ€™s Core Data Science team.

- Prophet is a procedure for forecasting time series data based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects. 

- Prophet works best with time series that have strong seasonal effects and several seasons of historical data.

<br><br>
### <font color=White> 1. Perform imports:</font>
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import datetime
from fbprophet import Prophet

#make our figures more readable
pd.options.display.float_format = '{:,.2f}'.format

"""<br><br>
### <font color=White>2. Import the dataset </font>
"""

from google.colab import files
  uploaded = files.upload()

# Once your file is on the Virtual Machine, you can check if the file is there.
!ls

"""<br><br>
### <font color=White>**3. Declare the dataset as a data frame and visualise it**</font>
"""

import io
ts_data = pd.read_csv(io.BytesIO(uploaded['API_IS.AIR.PSGR_DS2_en_csv_v2_3358196.csv']), skiprows=4)
ts_data.head(5)

ts_data.shape

ts_data['Indicator Name'].value_counts()

#drop non-necessary columns, and columns where data is always incomplete
drop_cols = ['Country Code', 'Indicator Name', 'Indicator Code',
       '1960', '1961', '1962', '1963', '1964', '1965', '1966', '1967', '1968',
       '1969', '2020', 'Unnamed: 65']

#create "prep" df, to be used for analysis
ts_data_prep = ts_data.drop(columns=drop_cols).copy()

#drop missing values (this is a very simplistic solution, other solutions such as inputing could have been used)
ts_data_prep.dropna(inplace=True)

#by running the shape method, we can see we are left with 106 rows & 51 columns, while we started with 266 and 66
ts_data_prep.shape

#let's melt the dataframe so that the df is prepped for Prophet
ts_data_prep = ts_data_prep.melt(id_vars='Country Name').rename(columns={'variable':'Year'})

#let's pick 2 countries: BE and USA
ts_data_prep_be = ts_data_prep.loc[ts_data_prep['Country Name'] == 'Belgium']
ts_data_prep_us = ts_data_prep.loc[ts_data_prep['Country Name'] == 'United States']

"""<br><br>
### <font color=White>**4. Take a look at the descriptive stats**</font>

* What is the min/average/max numbe of passengers per year?

"""

ts_data_prep_be.describe()

#BE
# Create a histogram to observe the distribution of passengers per year
ts_data_prep_be['value'].hist(color='blue', alpha=0.5, bins=20)

# Add labels
plt.title('Histogram')
plt.xlabel('Passengers per year')
plt.ylabel('Frequency')

#data looks quite spread out

# Create a line chart to observe the evolution of passengers (per year)

ts_data_prep_be.set_index('Year').plot(color='blue', alpha=0.5)

#the graph shows a clear drop in 2001, we can deduce it most likely has something to do with 9/11

#US
# Create a histogram to observe the distribution of passengers per year
ts_data_prep_us['value'].hist(color='blue', alpha=0.5, bins=20)

# Add labels
plt.title('Histogram')
plt.xlabel('Passengers per year')
plt.ylabel('Frequency')

#data looks quite spread out

# Create a line chart to observe the evolution of passengers (per year)

ts_data_prep_us.set_index('Year').plot(color='blue', alpha=0.5)

#surprisingly, the drop in 2000 is much less pronounced in the US than in Belgium.
#this is the point where having a chat with a domain expert is important
#since we don't have that option, let's pick another country to see the pattern there

#france looks like the US [not showing it, but DE and IT also look closer to the US than to BE]
#belgium could be an outlier, so to be safe let's replace it with France
ts_data_prep_fr = ts_data_prep.loc[ts_data_prep['Country Name'] == 'France']
ts_data_prep_fr.set_index('Year').plot(color='blue', alpha=0.5)

"""<br><br>
### <font color=White>5. Declare the variable to predict (*y*) and the date (*ds*) </font>
"""

#let's prepare the data for Prophet
ts_pred_fr = ts_data_prep_fr.iloc[:,1:]
ts_pred_fr.columns = ["ds", "y"]
ts_pred_fr.head(5)

"""<br><br>
### <font color=White>6. Making a prediction </font>

* Create the first model ($m_1$) and fit the data to our dataframe:
"""

#one important parameter for the model is growth, which function to use
#default is linear, which assumes a linear growth (see below cell)
#realistically, this is a very optimistic function, as economies get richer, and
#air travel gets more accessible, but there is such a thing as diminishing returns
#(if we look at the linear plots for DE and IT we can see them already)
#it's what FB call a "saturating forecast"
#this we can manage with some hyperparameter tuning (growth)
#and by picking cap & floor values

ts_pred_fr['cap'] = ts_data_prep_fr['value'].max()*1.1
ts_pred_fr['floor'] = ts_data_prep_fr['value'].min()*0.9

m2= Prophet(daily_seasonality=False, weekly_seasonality=False)
m2.fit(ts_pred_fr[['ds', 'y']])
future = m2.make_future_dataframe(periods=12, freq='Y')
forecast = m2.predict(future)
m2.plot(forecast);

m1= Prophet(growth='logistic', changepoint_prior_scale=1, daily_seasonality=False, weekly_seasonality=False)
m1.fit(ts_pred_fr)

"""<br><br>
* To tell **Prophet** how far to predict in the future, use  ```make_future_dataframe```. 
"""

# let's pick the prediction period, e.g. 12 years
future = m1.make_future_dataframe(periods=12, freq='Y')
future['cap'] = ts_data_prep_fr['value'].max()*1.1
future['floor'] = ts_data_prep_fr['value'].min()*0.9

# then make the forecast
forecast = m1.predict(future)

# To see the last 5 predicted values:
forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper','floor','cap']].tail()

# Plot the data
m1.plot(forecast);

#looking at the graph, our POC model looks plausible (albeit, certainly improvable)
#most dots (datapoints) lie within the blue band, our confidence interval

#let's repeat for the US

ts_pred_us = ts_data_prep_us.iloc[:,1:]
ts_pred_us.columns = ["ds", "y"]

ts_pred_us['cap'] = ts_data_prep_us['value'].max()*1.1
ts_pred_us['floor'] = ts_data_prep_us['value'].min()*0.9

m1_us= Prophet(growth='logistic', changepoint_prior_scale=1, daily_seasonality=False, weekly_seasonality=False)
m1_us.fit(ts_pred_us)

future_us = m1.make_future_dataframe(periods=12, freq='Y')
future_us['cap'] = ts_data_prep_us['value'].max()*1.1
future_us['floor'] = ts_data_prep_us['value'].min()*0.9

# then make the forecast
forecast_us = m1_us.predict(future_us)
m1_us.plot(forecast_us);

# as for france, the US model seems belivable if we look at the past, but the last
# few years before 2019 saw a surge in growth, which the model is not capturing
# this should usggest us that the model could be a bit conservative, 
# and in future iterations we should either tune the hyperparameters better or pick a different model

#let's generate an export file with the predictions, so we can compare
forecast = forecast.rename(columns={'yhat':'pred_fr'})
forecast_export = forecast.tail(12)[['ds', 'pred_fr']].merge(forecast_us[['ds', 'yhat']], on='ds', how='left').rename(columns={'yhat':'pred_us'})
forecast_export

forecast_export

"""Looking at the curve, and at the predicted values, France is supposed to grow slightly faster than the US, meaning our "resource allocation informer tool" suggests we should prioritize it (in this simplified example, ignoring anything except growth rates in carried passengers).
Let's take a quick look at some cross-validation metrics to assess whether our little tool is working.

<br><br>
### <font color=White>7. Diagnostics </font>

* Prophet includes functionality for time series cross validation to measure forecast error using historical data. 
* This is done by selecting cutoff points in the history, and for each of them fitting the model using data only up to that cutoff point. 
* We can then compare the forecasted values to the actual values. 
<br>
"""

# Cross-validation
from fbprophet.diagnostics import cross_validation
df_cv = cross_validation(m1, horizon = '12 y')
df_cv.head()

# Performance metrics
# if we look at errors in absolute terms, they are in the ballpark of millions
# however, if we look in percentage terms, we should be fairly satisfied with our
# little PoC, looking at this quick backtesting
from fbprophet.diagnostics import performance_metrics
df_p = performance_metrics(df_cv)
df_p.head()
df_p.mean(axis=0)

"""<br><br>
### <font color=White>**8. Saving the predictions**</font>
"""

#To download the file with the forecasts as a .csv
forecast_export.to_csv('forecast_export.csv')
files.download('forecast_export.csv')